{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import ast\n",
    "import re\n",
    "import json\n",
    "import chromadb\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.utils.function_calling import convert_pydantic_to_openai_function\n",
    "from langchain.agents import tool\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "from langsmith import traceable\n",
    "\n",
    "from commit import update\n",
    "from utils.utils import serialize_dict_to_json, deserialize_json_to_dict\n",
    "from utils.chunk import SimpleFixedLengthChunker\n",
    "from utils.compress import get_skeleton\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "sflc = SimpleFixedLengthChunker()\n",
    "\n",
    "def neighbors_by_relation(G, node, relation_type):\n",
    "    \n",
    "    neighbors = []\n",
    "    for u, v, data in G.edges(node, data=True):\n",
    "        if data.get('relation') == relation_type:\n",
    "            neighbor = v if u == node else u  # Handle undirected edges\n",
    "            neighbors.append(neighbor)\n",
    "    return neighbors\n",
    "\n",
    "def load_graph(pickle_path):\n",
    "    \"\"\"Loads a NetworkX DiGraph from a pickle file.\"\"\"\n",
    "    with open(pickle_path, \"rb\") as f:\n",
    "        graph = pickle.load(f)\n",
    "    return graph\n",
    "\n",
    "dataset = load_dataset(\"lahirum/SWE_Experimental\", split=\"train\")\n",
    "# filter = [0, 1, 2, 3, 4,5, 6, 7, 8, 9]\n",
    "# dataset = dataset.select(filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_function_classes(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            file_content = file.read()\n",
    "            parsed_data = ast.parse(file_content)\n",
    "    except Exception as e:  # Catch all types of exceptions\n",
    "        print(f\"Error in file {file_path}: {e}\")\n",
    "        return [], [], \"\"\n",
    "    info = []\n",
    "\n",
    "    for node in ast.walk(parsed_data):\n",
    "        if isinstance(node, ast.ClassDef):\n",
    "            info.append(node.name)\n",
    "           \n",
    "        elif isinstance(node, ast.FunctionDef) or isinstance(\n",
    "            node, ast.AsyncFunctionDef\n",
    "        ):\n",
    "            if node.name ==\"__init__\":\n",
    "                continue\n",
    "            info.append(node.name)             \n",
    "    return info\n",
    "\n",
    "import os\n",
    "\n",
    "def get_file_structure(root_dir: str) -> dict:\n",
    "    file_structure = {}\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "      paths = dirpath.split(\"/\")\n",
    "      \n",
    "      filenames = [file for file in filenames if file.endswith('.py')]\n",
    "      rel_path = os.path.join(root_dir, dirpath)\n",
    "      rel_path = \".\" if rel_path == \".\" else rel_path.replace(\"\\\\\", \"/\")\n",
    "      if \"test\" in dirpath:\n",
    "          continue\n",
    "      if not filenames:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "      filenames = [dirpath+\"/\"+file for file in filenames]\n",
    "      file_structure[dirpath] = filenames\n",
    "    return file_structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prompts\n",
    "import schema\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    "    #max_retries=2,\n",
    ")\n",
    "\n",
    "llm_deepseek = ChatDeepSeek(\n",
    "    model=\"deepseek-reasoner\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "llm_large = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_retries=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = JsonOutputFunctionsParser()\n",
    "\n",
    "model_extract = llm_large.bind(\n",
    "    functions=[convert_pydantic_to_openai_function(schema.SuspiciousComponentOutput)],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "\n",
    "extract_chain = prompts.prompt_extract | model_extract\n",
    "\n",
    "model_select = llm.bind(\n",
    "    functions=[convert_pydantic_to_openai_function(schema.FileSuspicionOutput)],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "select_chain = prompts.file_path_filter_prompt | model_select\n",
    "\n",
    "model_filter_list = llm.bind(\n",
    "    functions=[convert_pydantic_to_openai_function(schema.SuspiciousFilesOutputList)],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "filter_list_chain = prompts.get_suspicious_file_list_from_list_of_files_prompt | model_filter_list \n",
    "\n",
    "model_select_list = llm.bind(\n",
    "    functions=[convert_pydantic_to_openai_function(schema.SuspiciousFilesOutputList)],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "select_list_chain = prompts.suspicious_files_filter_list_usingclfn_prompt | model_select_list\n",
    "\n",
    "model_select_with_reason = llm.bind(\n",
    "    functions=[convert_pydantic_to_openai_function(schema.SuspiciousFileReasoningOutput)],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "\n",
    "select_with_reason_chain = prompts.suspicious_files_with_reason_prompt | model_select_with_reason\n",
    "\n",
    "model_select_directory = llm.bind(\n",
    "    functions=[convert_pydantic_to_openai_function(schema.SuspiciousDirectoryOutput)],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "select_directory_chain = prompts.suspicious_directory_prompt | model_select_directory\n",
    "\n",
    "generate_multiple_descriptions = prompts.prompt_embedding_retriver | llm\n",
    "\n",
    "deep_reasoning_chain = prompts.deep_reasoning_prompt | llm_deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "commit_id = dataset[i]['base_commit']\n",
    "name = dataset[i]['instance_id'].split(\"__\")[0]\n",
    "problem_description = dataset[i]['problem_statement']\n",
    "graph = load_graph(f\"graph_{name}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 560\n",
      "\tPrompt Tokens: 528\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 32\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00164\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as callback:\n",
    "    result = extract_chain.invoke({\"problem_description\": problem_description})\n",
    "    # print(result)\n",
    "    print(callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'function_call': {'arguments': '{\"file\":\"django/db/migrations/operations/fields.py\",\"class_function_name\":\"AddField\"}', 'name': 'SuspiciousComponentOutput'}, 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 528, 'total_tokens': 560, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-BdzEqVnJLhQn3YwqKrwBRqMXuGn7R', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None} id='run--afee1f77-a916-4002-a1a3-bd1a411df094-0' usage_metadata={'input_tokens': 528, 'output_tokens': 32, 'total_tokens': 560, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from commit import update\n",
    "\n",
    "@traceable\n",
    "def start(inputs):\n",
    "    problem_description = inputs['problem_description']\n",
    "    name = inputs['name']\n",
    "    graph = inputs['graph'] \n",
    "    commit_id = inputs['commit_id']\n",
    "    graph = inputs['graph'] \n",
    "    update(name, commit_id)\n",
    "    with get_openai_callback() as callback:\n",
    "        result = extract_chain.invoke({\"problem_description\": problem_description})\n",
    "        print(callback)\n",
    "    result = result.additional_kwargs['function_call']['arguments']\n",
    "    result = json.loads(result)\n",
    "    result['name'] = name\n",
    "    result['problem_description'] = problem_description\n",
    "    result['graph'] = graph\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(start(problem_description, name,graph, commit_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.compress import get_skeleton\n",
    "import json\n",
    "\n",
    "@traceable\n",
    "def get_most_suspicious_files(inputs):\n",
    "    \"\"\"\n",
    "    Given a graph and a file, find the most suspicious files related to the given file.\n",
    "    \"\"\"\n",
    "    problem_description = inputs['problem_description']\n",
    "    graph = inputs['graph']\n",
    "    file = inputs['file']\n",
    "    if \"/\" in file:\n",
    "        file = file.split(\"/\")[-1]\n",
    "    if \".\" in file:\n",
    "        file = file.split(\".\")[0]\n",
    "    suspicious_files = []\n",
    "    for neighbor in neighbors_by_relation(graph, \"module_\"+file,  'path'):\n",
    "        if \"test\" in neighbor:\n",
    "            continue\n",
    "        suspicious_files.append(neighbor)\n",
    "    with get_openai_callback() as callback:  \n",
    "        filtered = select_chain.invoke({\"problem_description\": problem_description, \"file_list\": suspicious_files})\n",
    "        print(callback)\n",
    "    filtered = json.loads(filtered.additional_kwargs['function_call']['arguments'])\n",
    "    selected_file = filtered['suspicious_file']\n",
    "    candiate_structure = {}\n",
    "    for neighbor in neighbors_by_relation(graph, selected_file,  'imports')+[selected_file]:\n",
    "        try:\n",
    "            # with open(neighbor, \"r\", encoding=\"utf-8\") as f:\n",
    "            #     raw_code = f.read()\n",
    "            candiate_structure[neighbor] = extract_function_classes(neighbor)\n",
    "            # get_skeleton(raw_code, keep_constant = False, keep_indent=False, total_lines =15, prefix_lines=5,suffix_lines=5)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    with get_openai_callback() as callback:      \n",
    "        filtered_list = select_list_chain.invoke({\"problem_description\": problem_description, \"file_structure\": candiate_structure})\n",
    "        print(callback)\n",
    "    filtered_list = json.loads(filtered_list.additional_kwargs['function_call']['arguments'])\n",
    "    filtered_list = filtered_list['suspicious_files']\n",
    "    \n",
    "    filtered_candidate_structure = {}\n",
    "    for file in filtered_list:\n",
    "        try:\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                raw_code = f.read()\n",
    "            filtered_candidate_structure[file]=get_skeleton(raw_code, keep_constant = False, keep_indent=True, total_lines =15, prefix_lines=5,suffix_lines=5)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    with get_openai_callback() as callback:  \n",
    "        answer = select_with_reason_chain.invoke({\"problem_description\": problem_description, \"file_structure\": filtered_candidate_structure})\n",
    "        print(callback)\n",
    "    answer = json.loads(answer.additional_kwargs['function_call']['arguments'])\n",
    "        \n",
    "    return answer['suspicious_files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def pass_problem_description(inputs):\n",
    "    problem_description = inputs['problem_description']\n",
    "    return problem_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors_by_relation(graph, \"module_serializer\",  'path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def get_most_suspicious_files_using_clfn(inputs):\n",
    "    \"\"\"\n",
    "    Given a graph and a file, find the most suspicious files related to the given file.\n",
    "    \"\"\"\n",
    "    \n",
    "    problem_description = inputs['problem_description']\n",
    "    graph = inputs['graph']\n",
    "    class_function_name = inputs['class_function_name']\n",
    "    print(class_function_name)\n",
    "\n",
    "    if \".\" in class_function_name:\n",
    "        class_function_name = class_function_name.split(\".\")[0]\n",
    "    suspicious_files = []\n",
    "    for neighbor in neighbors_by_relation(graph, \"class_\"+class_function_name,  'class_path'):\n",
    "        if \"test\" in neighbor:\n",
    "            continue\n",
    "        suspicious_files.append(neighbor)\n",
    "    print(\"class\", suspicious_files)\n",
    "    # filtered = select_list_class_chain.invoke({\"problem_description\": problem_description, \"file_list\": suspicious_files})\n",
    "    # filtered = json.loads(filtered.additional_kwargs['function_call']['arguments'])\n",
    "    selected_file = suspicious_files #filtered['suspicious_files']\n",
    "    # print(selected_file)\n",
    "    \n",
    "    filtered_candidate_structure = {}\n",
    "    for file in selected_file:\n",
    "        try:\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                raw_code = f.read()\n",
    "            filtered_candidate_structure[file]=get_skeleton(raw_code, keep_constant = False, keep_indent=True, total_lines =15, prefix_lines=5,suffix_lines=5)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    with get_openai_callback() as callback:  \n",
    "        answer = select_with_reason_chain.invoke({\"problem_description\": problem_description, \"file_structure\": filtered_candidate_structure})\n",
    "        print(callback)\n",
    "    answer = json.loads(answer.additional_kwargs['function_call']['arguments'])\n",
    "        \n",
    "    return answer['suspicious_files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def get_most_suspicious_files_using_file_structure(inputs):\n",
    "    \"\"\"\n",
    "    Given a graph and a file, find the most suspicious files related to the given file.\n",
    "    \"\"\"\n",
    "    name = inputs['name']\n",
    "    problem_description = inputs['problem_description']\n",
    "    \n",
    "    file_structure = get_file_structure(name)\n",
    "    \n",
    "    directories = file_structure.keys()\n",
    "    with get_openai_callback() as callback:  \n",
    "        filtered = select_directory_chain.invoke({\"problem_description\": problem_description, \"directory_list\": directories})\n",
    "        print(callback)\n",
    "    filtered = json.loads(filtered.additional_kwargs['function_call']['arguments'])\n",
    "    selected_directory = filtered['suspicious_directory']\n",
    "    if selected_directory in file_structure:\n",
    "        suspicious_files = file_structure[selected_directory]\n",
    "    elif name + \"/\" + selected_directory in file_structure:\n",
    "        suspicious_files = file_structure[name + \"/\" + selected_directory]\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    print(len(suspicious_files))\n",
    "    candiate_structure = {}\n",
    "    for file in suspicious_files:\n",
    "        try:\n",
    "            candiate_structure[file] = extract_function_classes(file)\n",
    "            # get_skeleton(raw_code, keep_constant = False, keep_indent=False, total_lines =15, prefix_lines=5,suffix_lines=5)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    with get_openai_callback() as callback:    \n",
    "        filtered_list = select_list_chain.invoke({\"problem_description\": problem_description, \"file_structure\": candiate_structure})\n",
    "        print(callback)\n",
    "    filtered_list = json.loads(filtered_list.additional_kwargs['function_call']['arguments'])\n",
    "    filtered_list = filtered_list['suspicious_files']\n",
    "    \n",
    "    \n",
    "    filtered_candidate_structure = {}\n",
    "    for file in filtered_list:\n",
    "        try:\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                raw_code = f.read()\n",
    "            filtered_candidate_structure[file]=get_skeleton(raw_code, keep_constant = False, keep_indent=True, total_lines =15, prefix_lines=5,suffix_lines=5)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    with get_openai_callback() as callback:\n",
    "        answer = select_with_reason_chain.invoke({\"problem_description\": problem_description, \"file_structure\": filtered_candidate_structure})\n",
    "        print(callback)\n",
    "    answer = json.loads(answer.additional_kwargs['function_call']['arguments'])\n",
    "    print(\"file\", answer['suspicious_files'])\n",
    "        \n",
    "    return answer['suspicious_files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def embedding_retriever(inputs):\n",
    "    problem_description = inputs['problem_description']\n",
    "    name = inputs['name']\n",
    "\n",
    "    with get_openai_callback() as callback:\n",
    "        multiple_descriptions = generate_multiple_descriptions.invoke({\"problem_description\": inputs[\"problem_description\"]})\n",
    "        print(callback)\n",
    "\n",
    "    problem_description = \\\n",
    "        f\"\"\"## **Original GitHub issue description**:\\n\\n{inputs[\"problem_description\"]}\\n\\n\\n## **Generated descriptions**:\\n\\n{multiple_descriptions.content}\"\"\"\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "    chroma_client = chromadb.PersistentClient(f\"chroma_db\")\n",
    "    collection = chroma_client.get_collection(name=f\"{name}_chroma_index\")\n",
    "\n",
    "    vector_store = Chroma(\n",
    "        client=chroma_client,\n",
    "        collection_name=f\"{name}_chroma_index\",\n",
    "        embedding_function=embeddings,\n",
    "    )\n",
    "\n",
    "    results = vector_store.similarity_search(problem_description, k=10,)\n",
    "    # results = vector_store.max_marginal_relevance_search(problem_description, k=10, lambda_mult=0.5)\n",
    "\n",
    "    file = deserialize_json_to_dict(\"django_file_ids.json\")\n",
    "    structure = {}\n",
    "    for result in results:\n",
    "        file_ids = file[result.metadata[\"filename\"]].split(\":\")\n",
    "        chunk_docs_of_file = vector_store.get_by_ids(file_ids)\n",
    "        structure[result.metadata['filename']] = get_skeleton(sflc.dechunk_docs(chunk_docs_of_file))\n",
    "        \n",
    "    with get_openai_callback() as callback:\n",
    "        answer = select_with_reason_chain.invoke({\"problem_description\": problem_description, \"file_structure\": structure})\n",
    "        print(callback)\n",
    "    answer = json.loads(answer.additional_kwargs['function_call']['arguments'])\n",
    "\n",
    "    return answer['suspicious_files']\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(embedding_retriever({\"problem_description\":problem_description, \"name\": name}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def final_reasoning(inputs):\n",
    "    candidates = []\n",
    "    if inputs['get_suspicious_files']:\n",
    "        candidates.extend(inputs['get_suspicious_files'])\n",
    "    if inputs['get_suspicious_files_using_clfn']:\n",
    "        candidates.extend(inputs['get_suspicious_files_using_clfn'])\n",
    "    if inputs['get_suspicious_files_using_file_structure']:\n",
    "        candidates.extend(inputs['get_suspicious_files_using_file_structure'])\n",
    "    if inputs['embedding_retriever']:   \n",
    "        candidates.extend(inputs['embedding_retriever'])\n",
    "    \n",
    "    for c in candidates:\n",
    "        print(c)\n",
    "    problem_description = inputs['problem_description']\n",
    "    with get_openai_callback() as callback:  \n",
    "        result = deep_reasoning_chain.invoke({\"problem_description\": problem_description, \"candidates\": candidates})\n",
    "        print(callback)\n",
    "    result = result.content\n",
    "    \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableParallel, RunnableSequence\n",
    "\n",
    "start_run = RunnableLambda(start)\n",
    "pass_problem_description_run = RunnableLambda(pass_problem_description)\n",
    "get_suspicious_files_run = RunnableLambda(get_most_suspicious_files)\n",
    "get_suspicious_files_using_clfn_run = RunnableLambda(get_most_suspicious_files_using_clfn)\n",
    "get_suspicious_files_using_file_structure_run = RunnableLambda(get_most_suspicious_files_using_file_structure)\n",
    "embedding_retriever_run = RunnableLambda(embedding_retriever)\n",
    "final_reasoning_run = RunnableLambda(final_reasoning)\n",
    "\n",
    "parallel_run = RunnableParallel(\n",
    "    {\n",
    "        \"get_suspicious_files\": get_suspicious_files_run,\n",
    "        \"get_suspicious_files_using_clfn\": get_suspicious_files_using_clfn_run,\n",
    "        \"get_suspicious_files_using_file_structure\": get_suspicious_files_using_file_structure_run,\n",
    "        \"embedding_retriever\": embedding_retriever_run,\n",
    "        'problem_description': pass_problem_description_run\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "django\n",
      "DiGraph with 26295 nodes and 33405 edges\n",
      "Node 'django/django/apps/__init__.py' does not exist.\n",
      "Node 'django/django/conf/locale/__init__.py' does not exist.\n",
      "Node 'django/django/conf/locale/ar/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/ar_DZ/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/az/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/bg/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/bn/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/bs/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/ca/formats.py' does not exist.\n",
      "Node 'django/django/contrib/sitemaps/management/__init__.py' does not exist.\n",
      "Node 'django/django/conf/locale/cs/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/cy/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/da/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/de/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/de_CH/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/el/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/en/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/en_AU/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/en_GB/formats.py' does not exist.\n",
      "Node 'django/django/contrib/sitemaps/management/commands/__init__.py' does not exist.\n",
      "Node 'django/django/conf/locale/eo/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/es/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/es_AR/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/es_CO/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/es_MX/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/es_NI/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/es_PR/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/et/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/eu/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/fa/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/fi/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/fr/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/ga/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/gd/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/gl/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/he/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/hi/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/hr/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/hu/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/id/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/ig/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/is/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/it/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/ja/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/ka/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/km/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/kn/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/ko/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/ky/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/lt/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/lv/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/mk/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/ml/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/mn/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/ms/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/nb/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/nl/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/nn/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/pl/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/pt/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/pt_BR/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/ro/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/ru/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/sk/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/sl/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/sq/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/sr/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/sr_Latn/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/sv/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/ta/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/te/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/tg/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/th/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/tk/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/tr/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/uk/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/uz/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/vi/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/zh_Hans/formats.py' does not exist.\n",
      "Node 'django/django/conf/locale/zh_Hant/formats.py' does not exist.\n",
      "Node 'django/django/contrib/admindocs/urls.py' does not exist.\n",
      "Node 'django/django/contrib/gis/db/backends/postgis/const.py' does not exist.\n",
      "Node 'django/django/contrib/gis/db/models/__init__.py' does not exist.\n",
      "Node 'django/django/contrib/gis/forms/__init__.py' does not exist.\n",
      "Node 'django/django/contrib/gis/sitemaps/__init__.py' does not exist.\n",
      "Node 'django/django/http/__init__.py' does not exist.\n",
      "Node 'django/django/test/__init__.py' does not exist.\n",
      "Node 'django/django/views/__init__.py' does not exist.\n",
      "Node 'django/setup.py' does not exist.\n",
      "Node 'django/tests/admin_changelist/urls.py' does not exist.\n",
      "Node 'django/tests/admin_custom_urls/urls.py' does not exist.\n",
      "Node 'django/tests/admin_docs/namespace_urls.py' does not exist.\n",
      "Node 'django/tests/admin_docs/urls.py' does not exist.\n",
      "Node 'django/tests/admin_inlines/urls.py' does not exist.\n",
      "Node 'django/tests/admin_scripts/complex_app/models/__init__.py' does not exist.\n",
      "Node 'django/tests/admin_scripts/configured_settings_manage.py' does not exist.\n",
      "Node 'django/tests/admin_scripts/simple_app/models.py' does not exist.\n",
      "Node 'django/tests/admin_scripts/urls.py' does not exist.\n",
      "Node 'django/tests/admin_utils/urls.py' does not exist.\n",
      "Node 'django/tests/admin_widgets/urls.py' does not exist.\n",
      "Node 'django/tests/auth_tests/backend_alias.py' does not exist.\n",
      "Node 'django/tests/auth_tests/models/__init__.py' does not exist.\n",
      "Node 'django/tests/auth_tests/settings.py' does not exist.\n",
      "Node 'django/tests/auth_tests/urls_admin.py' does not exist.\n",
      "Node 'django/tests/builtin_server/urls.py' does not exist.\n",
      "Node 'django/tests/check_framework/urls/bad_error_handlers_invalid_path.py' does not exist.\n",
      "Node 'django/tests/check_framework/urls/beginning_with_slash.py' does not exist.\n",
      "Node 'django/tests/check_framework/urls/contains_tuple.py' does not exist.\n",
      "Node 'django/tests/check_framework/urls/include_contains_tuple.py' does not exist.\n",
      "Node 'django/tests/check_framework/urls/include_with_dollar.py' does not exist.\n",
      "Node 'django/tests/check_framework/urls/name_with_colon.py' does not exist.\n",
      "Node 'django/tests/check_framework/urls/no_warnings.py' does not exist.\n",
      "Node 'django/tests/check_framework/urls/no_warnings_i18n.py' does not exist.\n",
      "Node 'django/tests/check_framework/urls/non_unique_namespaces.py' does not exist.\n",
      "Node 'django/tests/check_framework/urls/path_compatibility/beginning_with_caret.py' does not exist.\n",
      "Node 'django/tests/check_framework/urls/path_compatibility/contains_re_named_group.py' does not exist.\n",
      "Node 'django/tests/check_framework/urls/path_compatibility/ending_with_dollar.py' does not exist.\n",
      "Node 'django/tests/check_framework/urls/unique_namespaces.py' does not exist.\n",
      "Node 'django/tests/check_framework/urls/warning_in_include.py' does not exist.\n",
      "Node 'django/tests/conditional_processing/urls.py' does not exist.\n",
      "Node 'django/tests/contenttypes_tests/urls.py' does not exist.\n",
      "Node 'django/tests/context_processors/urls.py' does not exist.\n",
      "Node 'django/tests/csrf_tests/csrf_token_error_handler_urls.py' does not exist.\n",
      "Node 'django/tests/file_storage/urls.py' does not exist.\n",
      "Node 'django/tests/file_uploads/urls.py' does not exist.\n",
      "Node 'django/tests/flatpages_tests/absolute_urls.py' does not exist.\n",
      "Node 'django/tests/flatpages_tests/no_slash_urls.py' does not exist.\n",
      "Node 'django/tests/flatpages_tests/settings.py' does not exist.\n",
      "Node 'django/tests/flatpages_tests/urls.py' does not exist.\n",
      "Node 'django/tests/foreign_object/models/__init__.py' does not exist.\n",
      "Node 'django/tests/forms_tests/urls.py' does not exist.\n",
      "Node 'django/tests/generic_inline_admin/urls.py' does not exist.\n",
      "Node 'django/tests/generic_views/urls.py' does not exist.\n",
      "Node 'django/tests/gis_tests/admin.py' does not exist.\n",
      "Node 'django/tests/gis_tests/geoadmin/urls.py' does not exist.\n",
      "Node 'django/tests/gis_tests/geoadmin_deprecated/urls.py' does not exist.\n",
      "Node 'django/tests/gis_tests/geoapp/sitemaps.py' does not exist.\n",
      "Node 'django/tests/gis_tests/geoapp/urls.py' does not exist.\n",
      "Node 'django/tests/handlers/urls.py' does not exist.\n",
      "Node 'django/tests/i18n/commands/__init__.py' does not exist.\n",
      "Node 'django/tests/i18n/other/locale/fr/formats.py' does not exist.\n",
      "Node 'django/tests/i18n/patterns/urls/default.py' does not exist.\n",
      "Node 'django/tests/i18n/patterns/urls/disabled.py' does not exist.\n",
      "Node 'django/tests/i18n/patterns/urls/included.py' does not exist.\n",
      "Node 'django/tests/i18n/patterns/urls/namespace.py' does not exist.\n",
      "Node 'django/tests/i18n/patterns/urls/path_unused.py' does not exist.\n",
      "Node 'django/tests/i18n/patterns/urls/wrong.py' does not exist.\n",
      "Node 'django/tests/i18n/patterns/urls/wrong_namespace.py' does not exist.\n",
      "Node 'django/tests/i18n/sampleproject/manage.py' does not exist.\n",
      "Node 'django/tests/i18n/unchanged/__init__.py' does not exist.\n",
      "Node 'django/tests/i18n/urls.py' does not exist.\n",
      "Node 'django/tests/i18n/urls_default_unprefixed.py' does not exist.\n",
      "Node 'django/tests/logging_tests/urls.py' does not exist.\n",
      "Node 'django/tests/logging_tests/urls_i18n.py' does not exist.\n",
      "Node 'django/tests/middleware/cond_get_urls.py' does not exist.\n",
      "Node 'django/tests/middleware/extra_urls.py' does not exist.\n",
      "Node 'django/tests/middleware/urls.py' does not exist.\n",
      "Node 'django/tests/middleware_exceptions/urls.py' does not exist.\n",
      "Node 'django/tests/gis_tests/geoadmin_deprecated/__init__.py' does not exist.\n",
      "Node 'django/tests/requests/__init__.py' does not exist.\n",
      "Node 'django/tests/model_meta/results.py' does not exist.\n",
      "Node 'django/tests/model_package/models/__init__.py' does not exist.\n",
      "Node 'django/tests/postgres_tests/integration_settings.py' does not exist.\n",
      "Node 'django/tests/project_template/urls.py' does not exist.\n",
      "Node 'django/tests/proxy_models/admin.py' does not exist.\n",
      "Node 'django/tests/proxy_models/urls.py' does not exist.\n",
      "Node 'django/tests/redirects_tests/urls.py' does not exist.\n",
      "Node 'django/tests/servers/urls.py' does not exist.\n",
      "Node 'django/tests/shortcuts/urls.py' does not exist.\n",
      "Node 'django/tests/sitemaps_tests/urls/empty.py' does not exist.\n",
      "Node 'django/tests/sitemaps_tests/urls/index_only.py' does not exist.\n",
      "Node 'django/tests/sitemaps_tests/urls/sitemap_only.py' does not exist.\n",
      "Node 'django/tests/staticfiles_tests/settings.py' does not exist.\n",
      "Node 'django/tests/staticfiles_tests/urls/default.py' does not exist.\n",
      "Node 'django/tests/syndication_tests/urls.py' does not exist.\n",
      "Node 'django/tests/template_tests/alternate_urls.py' does not exist.\n",
      "Node 'django/tests/template_tests/urls.py' does not exist.\n",
      "Node 'django/tests/test_client/urls.py' does not exist.\n",
      "Node 'django/tests/test_client_regress/urls.py' does not exist.\n",
      "Node 'django/tests/test_sqlite.py' does not exist.\n",
      "Node 'django/tests/test_utils/urls.py' does not exist.\n",
      "Node 'django/tests/timezones/urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns/converter_urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns/included_urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns/more_urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns/path_base64_urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns/path_dynamic_urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns/path_same_name_urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns/path_urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns_reverse/erroneous_urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns_reverse/extra_urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns_reverse/included_app_urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns_reverse/included_named_urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns_reverse/included_named_urls2.py' does not exist.\n",
      "Node 'django/tests/urlpatterns_reverse/included_namespace_urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns_reverse/included_no_kwargs_urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns_reverse/included_urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns_reverse/included_urls2.py' does not exist.\n",
      "Node 'django/tests/urlpatterns_reverse/named_urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns_reverse/named_urls_conflict.py' does not exist.\n",
      "Node 'django/tests/urlpatterns_reverse/namespace_urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns_reverse/reverse_lazy_urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns_reverse/urlconf_outer.py' does not exist.\n",
      "Node 'django/tests/urlpatterns_reverse/urls.py' does not exist.\n",
      "Node 'django/tests/urlpatterns_reverse/urls_error_handlers.py' does not exist.\n",
      "Node 'django/tests/urlpatterns_reverse/urls_without_handlers.py' does not exist.\n",
      "Node 'django/tests/urlpatterns_reverse/views_broken.py' does not exist.\n",
      "Node 'django/tests/user_commands/urls.py' does not exist.\n",
      "Node 'django/tests/utils_tests/test_module/another_bad_module.py' does not exist.\n",
      "Node 'django/tests/utils_tests/test_module/another_good_module.py' does not exist.\n",
      "Node 'django/tests/utils_tests/test_module/bad_module.py' does not exist.\n",
      "Node 'django/tests/utils_tests/test_module/child_module/grandchild_module.py' does not exist.\n",
      "Node 'django/tests/utils_tests/test_module/good_module.py' does not exist.\n",
      "Node 'django/tests/view_tests/default_urls.py' does not exist.\n",
      "Node 'django/tests/view_tests/generic_urls.py' does not exist.\n",
      "Node 'django/tests/view_tests/regression_21530_urls.py' does not exist.\n",
      "Node 'django/tests/view_tests/urls.py' does not exist.\n",
      "Checked out to 4a72da71001f154ea60906a2f74898d32b7322a7\n",
      "DiGraph with 27520 nodes and 35185 edges\n",
      "Tokens Used: 560\n",
      "\tPrompt Tokens: 528\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 32\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00164\n",
      "AddField\n",
      "class ['django/django/db/migrations/operations/fields.py']\n",
      "Tokens Used: 485\n",
      "\tPrompt Tokens: 463\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 22\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $8.264999999999999e-05\n",
      "Error in file appname/models.py: [Errno 2] No such file or directory: 'appname/models.py'\n",
      "Tokens Used: 515\n",
      "\tPrompt Tokens: 490\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 25\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $8.85e-05\n",
      "Tokens Used: 2385\n",
      "\tPrompt Tokens: 2360\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 25\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0003689999999999999\n",
      "14\n",
      "Tokens Used: 1552\n",
      "\tPrompt Tokens: 1410\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 142\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00029669999999999995\n",
      "Tokens Used: 647\n",
      "\tPrompt Tokens: 543\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 104\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00014385\n",
      "Tokens Used: 2192\n",
      "\tPrompt Tokens: 2140\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 52\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0003522\n",
      "Tokens Used: 2734\n",
      "\tPrompt Tokens: 2514\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 220\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0005091\n",
      "file [{'file': 'django/django/db/migrations/migration.py', 'reason': \"This file contains the Migration class which is responsible for defining migration operations, including adding fields to models. The issue arises from the incorrect reference to the default value for the 'capabilities' field, which is likely handled in this file during the migration process.\"}, {'file': 'django/django/db/migrations/autodetector.py', 'reason': \"This file is responsible for detecting changes in the model and generating the appropriate migration operations. The incorrect default value being passed during the migration could be a result of how the autodetector interprets the model's structure, particularly the nested class structure of 'Capability'.\"}, {'file': 'django/django/db/migrations/graph.py', 'reason': 'This file manages the migration graph, which includes dependencies and relationships between migrations. If the migration is incorrectly referencing the default value, it could be due to how the migration graph is constructed, particularly in relation to nested classes and their references.'}]\n",
      "Tokens Used: 1696\n",
      "\tPrompt Tokens: 332\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 1364\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0008682\n",
      "Tokens Used: 14697\n",
      "\tPrompt Tokens: 14443\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 254\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00231885\n",
      "{'file': 'appname/models.py', 'reason': \"The issue arises from the incorrect reference to the default method of the nested Capability class. The file 'appname/models.py' contains the definition of the Profile model and its nested Capability class. Since the migration is incorrectly referencing 'appname.models.Capability.default' instead of 'appname.models.Profile.Capability.default', this file is directly related to the problem.\"}\n",
      "{'file': 'django/django/db/migrations/operations/fields.py', 'reason': \"The issue arises from the incorrect reference to the default method of the nested class Capability in the migration. The AddField class in fields.py is responsible for handling the addition of fields in migrations, including their defaults. Since the migration is incorrectly referencing 'appname.models.Capability.default' instead of 'appname.models.Profile.Capability.default', this file is directly related to the problem. The constructor of AddField and its methods likely need to be examined to ensure that the correct model path is being used for nested classes.\"}\n",
      "{'file': 'django/django/db/migrations/migration.py', 'reason': \"This file contains the Migration class which is responsible for defining migration operations, including adding fields to models. The issue arises from the incorrect reference to the default value for the 'capabilities' field, which is likely handled in this file during the migration process.\"}\n",
      "{'file': 'django/django/db/migrations/autodetector.py', 'reason': \"This file is responsible for detecting changes in the model and generating the appropriate migration operations. The incorrect default value being passed during the migration could be a result of how the autodetector interprets the model's structure, particularly the nested class structure of 'Capability'.\"}\n",
      "{'file': 'django/django/db/migrations/graph.py', 'reason': 'This file manages the migration graph, which includes dependencies and relationships between migrations. If the migration is incorrectly referencing the default value, it could be due to how the migration graph is constructed, particularly in relation to nested classes and their references.'}\n",
      "{'file': 'django/django/db/models/fields/__init__.py', 'reason': \"This file contains the definition of the Field class, which is responsible for handling field attributes in Django models. The issue arises from the incorrect assignment of the 'default' parameter in the ArrayField, which is a subclass of Field. Since the problem is related to how defaults are set for fields, this file is crucial for understanding the underlying mechanics.\"}\n",
      "{'file': 'django/django/db/migrations/autodetector.py', 'reason': 'This file is responsible for detecting changes in models and generating migrations accordingly. The issue described involves a migration that incorrectly references the default value for a field. Since the migration generation process is handled here, this file is likely to contain the logic that leads to the incorrect migration output.'}\n",
      "{'file': 'django/django/db/models/base.py', 'reason': 'This file contains the base Model class, which is essential for defining Django models. The issue involves a model (Profile) and its nested class (Capability). Since the problem is related to how the model is defined and how its fields are processed, this file is relevant to understanding the context of the issue.'}\n",
      "Tokens Used: 4614\n",
      "\tPrompt Tokens: 1172\n",
      "\t\tPrompt Tokens Cached: 128\n",
      "\tCompletion Tokens: 3442\n",
      "\t\tReasoning Tokens: 2589\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "full_flow = start_run | parallel_run | final_reasoning_run\n",
    "args = {\"problem_description\": problem_description, \"name\": name, \"graph\": graph, \"commit_id\": commit_id}\n",
    "result = full_flow.invoke(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Analysis of Candidate Files\n",
      "\n",
      "Based on the issue description, the core problem is that Django's migration system generates an incorrect reference (`appname.models.Capability.default`) for a nested class method used as a `Field.default`. The correct reference should include the parent class (`appname.models.Profile.Capability.default`). Below is the evaluation of each candidate file:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"file\": \"django/django/db/migrations/autodetector.py\",\n",
      "    \"confidence\": 90,\n",
      "    \"reasoning\": \"This file handles change detection and migration operation generation. The issue stems from improper path resolution for nested classes during default value serialization. Since the autodetector is responsible for introspecting model structures (including nested classes) and generating operation arguments, it's the most likely location where the parent class context is being dropped during reference construction. The high confidence comes from the fact that nested class handling must be implemented in the detection logic.\"\n",
      "  },\n",
      "  {\n",
      "    \"file\": \"django/django/db/migrations/operations/fields.py\",\n",
      "    \"confidence\": 75,\n",
      "    \"reasoning\": \"The AddField operation processes field parameters like default. While it receives the incorrect reference, the root cause is likely upstream during value serialization. However, this file could contain safeguards for nested class references or might benefit from additional context passing. Points deducted because the primary serialization failure probably occurs before operations are constructed.\"\n",
      "  },\n",
      "  {\n",
      "    \"file\": \"django/django/db/models/fields/__init__.py\",\n",
      "    \"confidence\": 50,\n",
      "    \"reasoning\": \"Field initialization handles default values, but the issue manifests in migration serialization, not runtime behavior. The field correctly stores the callable reference; the problem arises when this reference is serialized for migrations. Confidence is moderate since field classes might need adjustments to preserve nesting context during deconstruction.\"\n",
      "  },\n",
      "  {\n",
      "    \"file\": \"django/django/db/migrations/migration.py\",\n",
      "    \"confidence\": 20,\n",
      "    \"reasoning\": \"This file is a container for migration operations and doesn't handle path resolution or value serialization. Its role is executing operations, not generating them. Low confidence as modifying this wouldn't address the incorrect reference generation during migration creation.\"\n",
      "  },\n",
      "  {\n",
      "    \"file\": \"django/django/db/models/base.py\",\n",
      "    \"confidence\": 15,\n",
      "    \"reasoning\": \"While ModelBase handles model class creation, the issue is specific to migration serialization of nested class attributes. No evidence suggests model instantiation is involved. Low confidence since the problem occurs during migration generation, not model definition or runtime operation.\"\n",
      "  },\n",
      "  {\n",
      "    \"file\": \"django/django/db/migrations/graph.py\",\n",
      "    \"confidence\": 5,\n",
      "    \"reasoning\": \"Manages migration dependencies and execution order, not operation content generation. The incorrect reference is a value serialization issue, unrelated to dependency resolution. Near-zero confidence as this file doesn't interact with model attribute paths.\"\n",
      "  },\n",
      "  {\n",
      "    \"file\": \"appname/models.py\",\n",
      "    \"confidence\": 0,\n",
      "    \"reasoning\": \"The model definition is correct and follows Django conventions. Modifying this file would be a workaround (e.g., moving Capability out of Profile), not a framework fix. Confidence is zero since the issue is a Django core bug in migration tooling, not application code.\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "### Summary\n",
      "- **Top Candidate**: `autodetector.py` (90/100)  \n",
      "  The migration autodetection logic is almost certainly where nested class context is lost during reference serialization. This aligns with Django's architecture where change detection directly inspects model structures and generates operation arguments.\n",
      "  \n",
      "- **Secondary Candidate**: `fields.py` (75/100)  \n",
      "  While less likely than the autodetector, the operations file could be enhanced to better handle nested class paths if the autodetector passes incomplete context.\n",
      "\n",
      "- **Others**: Low confidence due to architectural roles unrelated to value serialization or nested class introspection. The application model file is irrelevant as the issue is framework-level.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#50 boundfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in result:\n",
    "#     print(r)\n",
    "#i =27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
