{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lahiru-menik/miniconda3/envs/agentless/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "from langchain.agents import tool\n",
    "\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import ast\n",
    "import re\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "load_dotenv()\n",
    "import commit\n",
    "\n",
    "def neighbors_by_relation(G, node, relation_type):\n",
    "    \n",
    "    neighbors = []\n",
    "    for u, v, data in G.edges(node, data=True):\n",
    "        if data.get('relation') == relation_type:\n",
    "            neighbor = v if u == node else u  # Handle undirected edges\n",
    "            neighbors.append(neighbor)\n",
    "    return neighbors\n",
    "\n",
    "def load_graph(pickle_path):\n",
    "    \"\"\"Loads a NetworkX DiGraph from a pickle file.\"\"\"\n",
    "    with open(pickle_path, \"rb\") as f:\n",
    "        graph = pickle.load(f)\n",
    "    return graph\n",
    "\n",
    "dataset = load_dataset(\"lahirum/SWE_Experimental\", split=\"train\")\n",
    "# filter = [0, 1, 2, 3, 4,5, 6, 7, 8, 9]\n",
    "# dataset = dataset.select(filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_function_classes(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            file_content = file.read()\n",
    "            parsed_data = ast.parse(file_content)\n",
    "    except Exception as e:  # Catch all types of exceptions\n",
    "        print(f\"Error in file {file_path}: {e}\")\n",
    "        return [], [], \"\"\n",
    "    info = []\n",
    "\n",
    "    for node in ast.walk(parsed_data):\n",
    "        if isinstance(node, ast.ClassDef):\n",
    "            info.append(node.name)\n",
    "           \n",
    "        elif isinstance(node, ast.FunctionDef) or isinstance(\n",
    "            node, ast.AsyncFunctionDef\n",
    "        ):\n",
    "            if node.name ==\"__init__\":\n",
    "                continue\n",
    "            info.append(node.name)             \n",
    "    return info\n",
    "\n",
    "import os\n",
    "\n",
    "def get_file_structure(root_dir: str) -> dict:\n",
    "    file_structure = {}\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "      paths = dirpath.split(\"/\")\n",
    "      \n",
    "      filenames = [file for file in filenames if file.endswith('.py')]\n",
    "      rel_path = os.path.join(root_dir, dirpath)\n",
    "      rel_path = \".\" if rel_path == \".\" else rel_path.replace(\"\\\\\", \"/\")\n",
    "      if not filenames:\n",
    "        continue\n",
    "      filenames = [dirpath+\"/\"+file for file in filenames]\n",
    "      file_structure[dirpath] = filenames\n",
    "    return file_structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prompts\n",
    "import schema\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    "    #max_retries=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_348359/3887551127.py:2: LangChainDeprecationWarning: The function `_convert_pydantic_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 1.0. Use :meth:`~langchain_core.utils.function_calling.convert_to_openai_function()` instead.\n",
      "  functions=[convert_pydantic_to_openai_function(schema.SuspiciousComponentOutput)],\n"
     ]
    }
   ],
   "source": [
    "parser = JsonOutputFunctionsParser()\n",
    "\n",
    "model_extract = llm.bind(\n",
    "    functions=[convert_pydantic_to_openai_function(schema.SuspiciousComponentOutput)],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "\n",
    "extract_chain = prompts.prompt_extract | model_extract\n",
    "\n",
    "model_select = llm.bind(\n",
    "    functions=[convert_pydantic_to_openai_function(schema.FileSuspicionOutput)],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "select_chain = prompts.file_path_filter_prompt | model_select\n",
    "\n",
    "model_filter_list = llm.bind(\n",
    "    functions=[convert_pydantic_to_openai_function(schema.SuspiciousFilesOutputList)],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "filter_list_chain = prompts.get_suspicious_file_list_from_list_of_files_prompt | model_filter_list \n",
    "\n",
    "model_select_list = llm.bind(\n",
    "    functions=[convert_pydantic_to_openai_function(schema.SuspiciousFilesOutputList)],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "select_list_chain = prompts.suspicious_files_filter_list_usingclfn_prompt | model_select_list\n",
    "\n",
    "model_select_with_reason = llm.bind(\n",
    "    functions=[convert_pydantic_to_openai_function(schema.SuspiciousFileReasoningOutput)],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "\n",
    "select_with_reason_chain = prompts.suspicious_files_with_reason_prompt | model_select_with_reason\n",
    "\n",
    "model_select_directory = llm.bind(\n",
    "    functions=[convert_pydantic_to_openai_function(schema.SuspiciousDirectoryOutput)],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "select_directory_chain = prompts.suspicious_directory_prompt | model_select_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "commit_id = dataset[i]['base_commit']\n",
    "name = dataset[i]['instance_id'].split(\"__\")[0]\n",
    "problem_description = dataset[i]['problem_statement']\n",
    "graph = load_graph(f\"graph_{name}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 436\n",
      "\tPrompt Tokens: 408\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 28\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $7.8e-05\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'function_call'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# print(result)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(callback)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madditional_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_call\u001b[49m\u001b[38;5;241m.\u001b[39marguments)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'function_call'"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as callback:\n",
    "    result = extract_chain.invoke({\"problem_description\": problem_description})\n",
    "    # print(result)\n",
    "    print(callback)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.compress import get_skeleton\n",
    "import json\n",
    "def get_most_suspicious_files(graph, file):\n",
    "    \"\"\"\n",
    "    Given a graph and a file, find the most suspicious files related to the given file.\n",
    "    \"\"\"\n",
    "    if \"/\" in file:\n",
    "        file = file.split(\"/\")[-1]\n",
    "    if \".\" in file:\n",
    "        file = file.split(\".\")[0]\n",
    "    suspicious_files = []\n",
    "    for neighbor in neighbors_by_relation(graph, \"module_\"+file,  'path'):\n",
    "        suspicious_files.append(neighbor)\n",
    "    filtered = select_chain.invoke({\"problem_description\": problem_description, \"file_list\": suspicious_files})\n",
    "    filtered = json.loads(filtered.additional_kwargs['function_call']['arguments'])\n",
    "    selected_file = filtered['suspicious_file']\n",
    "    candiate_structure = {}\n",
    "    for neighbor in neighbors_by_relation(graph, selected_file,  'imports')+[selected_file]:\n",
    "        try:\n",
    "            # with open(neighbor, \"r\", encoding=\"utf-8\") as f:\n",
    "            #     raw_code = f.read()\n",
    "            candiate_structure[neighbor] = extract_function_classes(neighbor)\n",
    "            # get_skeleton(raw_code, keep_constant = False, keep_indent=False, total_lines =15, prefix_lines=5,suffix_lines=5)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        \n",
    "    filtered_list = select_list_chain.invoke({\"problem_description\": problem_description, \"file_structure\": candiate_structure})\n",
    "    filtered_list = json.loads(filtered_list.additional_kwargs['function_call']['arguments'])\n",
    "    filtered_list = filtered_list['suspicious_files']\n",
    "    \n",
    "    filtered_candidate_structure = {}\n",
    "    for file in filtered_list:\n",
    "        try:\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                raw_code = f.read()\n",
    "            filtered_candidate_structure[file]=get_skeleton(raw_code, keep_constant = False, keep_indent=True, total_lines =15, prefix_lines=5,suffix_lines=5)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    answer = select_with_reason_chain.invoke({\"problem_description\": problem_description, \"file_structure\": filtered_candidate_structure})\n",
    "    answer = json.loads(answer.additional_kwargs['function_call']['arguments'])\n",
    "        \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_suspicious_files_using_file_structure(graph, problem_description, name):\n",
    "    \"\"\"\n",
    "    Given a graph and a file, find the most suspicious files related to the given file.\n",
    "    \"\"\"\n",
    "    file_structure = get_file_structure(name)\n",
    "    directories = file_structure.keys()\n",
    "    filtered = select_directory_chain.invoke({\"problem_description\": problem_description, \"directory_list\": directories})\n",
    "    filtered = json.loads(filtered.additional_kwargs['function_call']['arguments'])\n",
    "    selected_directory = filtered['suspicious_directory']\n",
    "    suspicious_files = file_structure[selected_directory] \n",
    "    \n",
    "    print(len(suspicious_files))\n",
    "    candiate_structure = {}\n",
    "    for file in suspicious_files:\n",
    "        try:\n",
    "            candiate_structure[file] = extract_function_classes(file)\n",
    "            # get_skeleton(raw_code, keep_constant = False, keep_indent=False, total_lines =15, prefix_lines=5,suffix_lines=5)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    with get_openai_callback() as callback:    \n",
    "        filtered_list = select_list_chain.invoke({\"problem_description\": problem_description, \"file_structure\": candiate_structure})\n",
    "        print(callback)\n",
    "    filtered_list = json.loads(filtered_list.additional_kwargs['function_call']['arguments'])\n",
    "    filtered_list = filtered_list['suspicious_files']\n",
    "    \n",
    "    \n",
    "    filtered_candidate_structure = {}\n",
    "    for file in filtered_list:\n",
    "        try:\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                raw_code = f.read()\n",
    "            filtered_candidate_structure[file]=get_skeleton(raw_code, keep_constant = False, keep_indent=True, total_lines =15, prefix_lines=5,suffix_lines=5)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    with get_openai_callback() as callback:\n",
    "        answer = select_with_reason_chain.invoke({\"problem_description\": problem_description, \"file_structure\": filtered_candidate_structure})\n",
    "        print(callback)\n",
    "    answer = json.loads(answer.additional_kwargs['function_call']['arguments'])\n",
    "        \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentless",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
